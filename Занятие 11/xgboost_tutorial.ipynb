{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='blue'>XGBoost</font> eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/dmlc/xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем датасет Boston Housing и обучим XGBoost на нем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from xgboost) (1.21.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: catboost in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (3.4.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (0.18.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (1.3.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (4.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (1.21.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: six in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.1-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wheel in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kzolo\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install catboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kzolo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost предлагает 2 способа использования алгоритмов:\n",
    "* sklearn-совместимые классы XGBClassifier, XGBRegressor\n",
    "\n",
    "* \"оригинальная\" python-библиотека"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on fold 0: 4.883007922349847\n",
      "RMSE on fold 1: 3.067504277609587\n"
     ]
    }
   ],
   "source": [
    "for fold_index, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "    xgb_model.fit(X[train_index], y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(\"RMSE on fold {}: {}\".format(fold_index, np.sqrt(mean_squared_error(actuals, predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:06:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "RMSE on fold 0: [0]\teval-rmse:7.434502\n",
      "[15:06:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:06:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "RMSE on fold 1: [0]\teval-rmse:9.167999\n"
     ]
    }
   ],
   "source": [
    "def get_params():\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"booster\"] = \"gbtree\"\n",
    "    params[\"eval_metric\"] = \"rmse\"\n",
    "    params[\"num_boost_round\"] = 100\n",
    "    params[\"max_depth\"] = 3\n",
    "    params[\"tree_method\"] = \"approx\"\n",
    "    params[\"sketch_eps\"] = 1\n",
    "    \n",
    "    return params\n",
    "    \n",
    "for fold_index, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    params = get_params()\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
    "    xgtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
    "    \n",
    "    bst = xgb.train(params, xgtrain) #аналог fit в sklearn\n",
    "\n",
    "    print(\"RMSE on fold {}: {}\".format(fold_index, bst.eval(xgtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Градиентный бустинг на решающих деревьях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Хотим построить композицию алгоритмов:\n",
    "<font size=5>\n",
    "\n",
    "$$ \\hat{y_i} = \\phi(x_i) = \\sum_{k=1}^{K} f_k(x_i) $$\n",
    "\n",
    "$$ Obj(f) = \\sum_{i} l(y_i, \\hat{y_i} ) + \\sum_k \\Omega(f_k)$$\n",
    "\n",
    "$$ \\Omega(f_k) = \\gamma T + \\frac{1}{2}\\lambda\\sum_{j=1}^{T}w_j^2 + \\alpha\\sum_{j=1}^{T}w_j$$\n",
    "\n",
    "\n",
    "<font size=3>\n",
    "\n",
    "$ x_i, y_i, \\hat{y_i} $ - i-ый объект, правильный ответ и предсказание модели для для него\n",
    "\n",
    "$ \\Omega $ - регуляризация\n",
    "\n",
    "T - количество листьев в дереве\n",
    "\n",
    "$ w_j $ - веса, проставленные в листьях дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преимущества:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* потенциально очень высокое качество во многих задачах\n",
    "\n",
    "* находит нелинейные связи\n",
    "\n",
    "* способен обработать датасеты с большим числом объектов и признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Недостатки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* очень много параметров\n",
    "\n",
    "* модели не интерпретируемы\n",
    "\n",
    "* по умолчанию не очень быстрый"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Особенности XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "Написан на C++, есть обертки на Python, R, Java, Scala\n",
    "\n",
    "С помощью XGBoost выиграна половина конкурсов на Kaggle\n",
    "\n",
    "Существует коммерческая версия TreeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "Для уменьшения переобучения целевая функция поддерживает L0, L1, L2 регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кастомные функции потерь / метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В XGBoost встроено множество различных функций потерь:\n",
    "\n",
    "* reg:linear\n",
    "\n",
    "* reg:logistic\n",
    "\n",
    "* binary:logistic\n",
    "\n",
    "* binary:logitraw\n",
    "\n",
    "* multi:softmax\n",
    "\n",
    "* rank:pairwise\n",
    "\n",
    "* ...\n",
    "\n",
    "А также соответствующих eval_metric, которые замеряют качество и позволяют сделать early stop.\n",
    "\n",
    "Но также имеется возможность реализовать свой objective и eval_metric.\n",
    "\n",
    "Все, что для этого нужно - уметь считать градиент и гессиан."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_reg_linear(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    grad = (preds - labels)\n",
    "    hess = np.ones(labels.shape[0])\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:06:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\teval-rmse:8.714170\n",
      "[15:06:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:06:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\teval-rmse:7.936395\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    params = get_params()\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
    "    xgtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
    "\n",
    "    bst = xgb.train(params, xgtrain, obj=my_reg_linear)\n",
    "    \n",
    "    predictions = bst.predict(xgtest)\n",
    "    actuals = y[test_index]\n",
    "\n",
    "    print(bst.eval(xgtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximated tree splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данных слишком много, то можно использовать не все значения признаков, а разделить их на бакеты.\n",
    "\n",
    "А именно, от каждого признака берутся не все значения, а только некоторое подмножество. Разбиение производится по элементам этого подмножества. \n",
    "\n",
    "Для разбиения выбираются взвешенные перцентили.\n",
    "\n",
    "В оригинальной статье указывается 2 алгоритма:\n",
    "*   глобальный - один раз выбрать разбиение значений фактора перед началом построения дерева и зафиксировать\n",
    "\n",
    "    экономим на выборе разбиений, но обычно приходится выбирать больше точек разбиения\n",
    "    \n",
    "    \n",
    "*   локальный - выбирать разбиение после каждого сплита\n",
    "  \n",
    "    работает лучше на глубоких деревьях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"tree_method\"] = \"approx\"\n",
    "params[\"sketch_eps\"] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пропуски в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost умеет обрабатывать разреженные матрицы\n",
    "\n",
    "Но категориальные признаки нужно приводить к числовому виду\n",
    "\n",
    "Нужно указать, какое число является \"пропуском\"\n",
    "\n",
    "При сплите, алгоритм смотрит в какую сторону лучше отвести объекты с пропуском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain_missed = xgb.DMatrix(X[test_index], label=y[test_index], missing=-999.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитывает сколько раз каждый признак использовался для использовался в вершине дерева при разбиении\n",
    "\n",
    "Это не качество фактора, а его важность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 8.0,\n",
       " 'f2': 5.0,\n",
       " 'f3': 6.0,\n",
       " 'f4': 3.0,\n",
       " 'f5': 1.0,\n",
       " 'f6': 7.0,\n",
       " 'f8': 8.0,\n",
       " 'f10': 2.0,\n",
       " 'f11': 7.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прунинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно GBM перестает разделять вершины дерева, когда gain становится отрицательным - жадный подход.\n",
    "Могло оказаться так, что после неудачного сплита с отрицательным gain'ом получится сделать сильно положительный сплит.\n",
    "\n",
    "XGBoost доводит деревья до max_depth, после чего начинает удалять сплиты, которые несут отрицательный вклад."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дообучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/data/data.cc:759: No format parameter is provided in input uri.  Choosing default parser in dmlc-core.  Consider providing a uri parameter like: filename?format=csv\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[15:06:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/data/data.cc:765: Encountered parser error:\n[15:06:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/dmlc-core/src/io/local_filesys.cc:86: LocalFileSystem.GetPathInfo: agaricus.txt.train error: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9372/3794191220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'agaricus.txt.train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'agaricus.txt.test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwatchlist\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# advanced: start from a initial base prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    699\u001b[0m                                  feature_types)\n\u001b[0;32m    700\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_uri\u001b[1;34m(data, missing, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m     _check_call(_LIB.XGDMatrixCreateFromFile(c_str(data),\n\u001b[0m\u001b[0;32m    617\u001b[0m                                              \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                                              ctypes.byref(handle)))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \"\"\"\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [15:06:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/data/data.cc:765: Encountered parser error:\n[15:06:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/dmlc-core/src/io/local_filesys.cc:86: LocalFileSystem.GetPathInfo: agaricus.txt.train error: No such file or directory"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix('agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('agaricus.txt.test')\n",
    "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "###\n",
    "# advanced: start from a initial base prediction\n",
    "#\n",
    "print ('start running example to start from a initial prediction')\n",
    "# specify parameters via map, definition are same as c++ version\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "# train xgboost for 1 round\n",
    "bst = xgb.train( param, dtrain, 1, watchlist )\n",
    "\n",
    "# Note: we need the margin value instead of transformed prediction in set_base_margin\n",
    "# do predict with output_margin=True, will always give you margin values before logistic transformation\n",
    "ptrain = bst.predict(dtrain, output_margin=True)\n",
    "ptest  = bst.predict(dtest, output_margin=True)\n",
    "\n",
    "dtrain.set_base_margin(ptrain)\n",
    "dtest.set_base_margin(ptest)\n",
    "\n",
    "print ('this is result of running from initial prediction')\n",
    "bst = xgb.train( param, dtrain, 1, watchlist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенная кросс валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.cv(param, dtrain, nfold = 4, num_boost_round=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 вида бустеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gbtree - обычные решающие деревья\n",
    "\n",
    "* gblinear - линейные модели\n",
    "\n",
    "* dart - решающие деревья, алгоритм может \"выбрасывать\" некоторые из деревьев, уменьшая переобучение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Веса для объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем учитывать каждый объект со своим весом, этот вес будет учитываться и при выборе бакетов при приближенном построении деревьев, при сплите, при подсчете Objective.\n",
    "\n",
    "Допустим, мы хотим классифицировать короткие сообщения.  Некоторые из них повторяются. В этом случае выгодно \"слить\" вместе все дубликаты и посчитать их один раз, но с большим весом. При неизменном качестве это уменьшит время обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = np.random.randint(low=1, high=5, size=X.shape[0])\n",
    "train_examples = 300\n",
    "\n",
    "\n",
    "X_train = X[:train_examples]\n",
    "X_test = X[train_examples:]\n",
    "y_train = y[:train_examples]\n",
    "y_test = y[train_examples:]\n",
    "\n",
    "\n",
    "X_train_repeated = np.repeat(X_train, repeats[:train_examples], axis=0)\n",
    "X_test_repeated = np.repeat(X_test, repeats[train_examples:], axis=0)\n",
    "y_train_repeated = np.repeat(y_train, repeats[:train_examples], axis=0)\n",
    "\n",
    "\n",
    "xgtrain_repeated = xgb.DMatrix(X_train_repeated, label=y_train_repeated)\n",
    "xgtrain_weighted = xgb.DMatrix(X_train, label=y_train, weight=repeats[:train_examples])\n",
    "\n",
    "xgtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "bst = xgb.train(params, xgtrain_repeated)\n",
    "print(\"Repeated dataset. Train size: {}, error: {}\".format(xgtrain_repeated.num_row(), bst.eval(xgtest)))\n",
    "\n",
    "bst = xgb.train(params, xgtrain_weighted)\n",
    "print(\"Weighted dataset. Train size: {}, error: {}\".format(xgtrain_weighted.num_row(), bst.eval(xgtest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Другие параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> learning_rates </i> - можно настроить убывающую скорость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "<i> max_depth </i> - максимальная глубина дерева. Слишком большая глубина ведет к переобучению\n",
    "\n",
    "<i> subsample, colsample_bytree, colsample_bylevel </i> - сэмплирование по объектам и признакам\n",
    "\n",
    "\n",
    "<i> min_child_weight </i> - минимальная сумма весов в листе\n",
    "\n",
    "<i> scale_pos_weight </i> - вес целого класса, используется если один класс заметно чаще встречается, чем другой\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные параметры для DART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "<i> sample_type </i> - стратегия выбора деревьев для выкидывания\n",
    "\n",
    "<i> rate_drop </i> - какую долю выкидываем\n",
    "\n",
    "<i> skip_drop </i> - шанс пропустить дроп на этой итерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настраиваем XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "* Выбираем относительно большую learning_rate ($ \\eta \\in [0.05, 0.3]$), подбираем оптимальное число деревьев для выбранного $ \\eta $\n",
    "\n",
    "* Настраиваем параметры деревьев, начиная с самых значимых (max_depth, min_child_weight, gamma, subsample, colsample_bytree)\n",
    "\n",
    "* Настраиваем регуляризации ($ \\lambda, \\alpha $)\n",
    "\n",
    "* Уменьшаем learning_rate, пропорционально увеличиваем число деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
